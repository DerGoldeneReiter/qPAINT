# Import modules
import numpy as np
import pandas as pd
import importlib

#%%
def _filter(df,q):
    """ 
    Kinetics filter for '_props' DataFrame as generated by pickprops.py. 
    Filter applies to following fields:
    
    'mean_frame':
        Drop values lower than percentile given by q
        Drop values higher than percentile given by 100-q
    'std_frame':
        Drop values lower than percentile given by q
    'mono_tau':
        Drop values higher than 2*median
    
    Parameters
    ---------
    df : pandas.DataFrame
        '_props' DataFrame as generated by pickprops.py
    q: float
        Lower percentile (in %) for filtering 'mean_frame' and 'std_frame'. Must be in range [0,100]
    Returns
    -------
    df_drop: pandas.DataFrame
        Filtered '_props' DataFrame
        
    """
    #### Function definitions percentiles
    from numpy import percentile as perc
    #### Function definition for dropping outliers
    def drop_out(df,q):
        #### Copy df
        df_dropped=df.copy()
        ####Remove groups with ...
        #### ... deviation between linear fit and exponential fit higher than 20%
        istrue=(np.abs(df_dropped.mono_tau_lin-df_dropped.mono_tau)/df_dropped.mono_tau_lin)>0.2
        df_dropped.drop(df_dropped.loc[istrue].index,inplace=True)
        #### ... mean_frame lower than q-percentile
        istrue=df_dropped.mean_frame<perc(df_dropped.mean_frame,q)
        #### ... or mean_frame higher than 100-q-percentile
        istrue=istrue | (df_dropped.mean_frame>perc(df_dropped.mean_frame,100-q))
        #### ... or std_frame lower than q-percentile
        istrue=istrue | (df_dropped.std_frame<perc(df_dropped.std_frame,q))
        df_dropped.drop(df_dropped.loc[istrue].index,inplace=True)
        #### Boolean: mono_tau higher than 2x50-percentile
        istrue=df_dropped.mono_tau>(2*perc(df_dropped.mono_tau,50))
        df_dropped.drop(df_dropped.loc[istrue].index,inplace=True)
        #### Boolean: n_events higher than 2x50-percentile
        istrue=df_dropped.n_events>(1.5*perc(df_dropped.n_events,50))
        df_dropped.drop(df_dropped.loc[istrue].index,inplace=True)
        
        return df_dropped
    
    ##### General radial filter if full chip is used
    if (df.mean_y.max()>490):
        istrue=((df.mean_x-512)**2+(df.mean_y-512)**2)>490**2
        df.drop(df[istrue].index,inplace=True)
    #### Apply 'drop_out' per expID
    df_drop=df.groupby(level=0).apply(lambda df: drop_out(df,q))
    #### Drop level=0 after groupby since it will just be repeated version of former level=0
    df_drop.index=df_drop.index.droplevel(level=0)
    
    return df_drop

#%%
def _stats(df,CycleTime):
    """ 
    
    
    Parameters
    ---------
    df : pandas.DataFrame
        '_props' DataFrame as generated by pickprops.py
    q: float
        Lower percentile (in %) for filtering 'mean_frame' and 'std_frame'. Must be in range [0,100]
    Returns
    -------
    df_drop: pandas.DataFrame
        Filtered '_props' DataFrame
        
    """
    #### List of observables
    out_vars=['expID','mono_tau_lin','mono_A_lin','tau_b','tau_d','mono_taub','mono_taud','n_events']
    #### List of statistical quantities
    out_stats=['25%','50%','75%','mean','std']
    #### List of observables that will be multiplied with CycleTime to convert from frame to seconds
    out_converts=['mono_tau_lin','mono_taub','mono_taud','tau_b','tau_d']
    
    #### Get statistics defined in out_stats in all variables defined in out_vars
    df_stats=df.groupby('expID').describe()
    df_stats=df_stats.loc[:,(out_vars,out_stats)]
    #### Apply unit conversion from frame to [s] to all tau values
    df_stats.loc[:,(out_converts,slice(None))]=df_stats.loc[:,(out_converts,slice(None))]*CycleTime
    #### Get deviation from percentiles to median
    df_stats.loc[:,(slice(None),'25%')]=df_stats.loc[:,(slice(None),'50%')].values-df_stats.loc[:,(slice(None),'25%')].values
    df_stats.loc[:,(slice(None),'75%')]=df_stats.loc[:,(slice(None),'75%')].values-df_stats.loc[:,(slice(None),'50%')].values
    df_stats.loc[:,(slice(None),'std')]=df_stats.loc[:,(slice(None),'std')].values/2
    ##### Add number of groups used for generation of stats
    df_stats.loc[:,'groups']=df.groupby('expID').size()
    ##### Add imager concentration
    df_stats.loc[:,'c']=df.groupby('expID').apply(lambda df: df.conc.mean()).values
    df_stats.rename(columns={'c':'conc'},inplace=True)
    
    return df_stats

#%%
def _fit_conc(df,df_stats,use_tau_stat='mean',use_A_stat='median',fix_SDS=False):
        
    from scipy.optimize import curve_fit
    import varfuncs
    importlib.reload(varfuncs)
    
    #### Which statistical quantity for mono_tau is used for fit 
    if use_tau_stat=='mean':
        center_tau='mean'
        low_tau='std'
        up_tau='std'
    elif use_tau_stat=='median':
        center_tau='50%'
        low_tau='25%'
        up_tau='75%'
    else:
        center_tau='mean'
        low_tau='std'
        up_tau='std'
    #### Which statistical quantity for mono_A is used for fit 
    if use_A_stat=='mean':
        center_A='mean'
        low_A='std'
        up_A='std'
    elif use_A_stat=='median':
        center_A='50%'
        low_A='25%'
        up_A='75%'
    else:
        center_A='50%'
        low_A='25%'
        up_A='75%'

    #### Get ariables for start paramter estimates
    minc=df_stats.conc.min()
    maxc=df_stats.conc.max()
    tau_minc=df_stats.loc[df_stats.conc==minc,('mono_tau_lin',center_tau)].mean()
    tau_maxc=df_stats.loc[df_stats.conc==maxc,('mono_tau_lin',center_tau)].mean()
    A_minc=df_stats.loc[df_stats.conc==minc,('mono_A_lin',center_A)].mean()
    minc=minc*1e-9 # Convert: [nM]->[M]
    maxc=maxc*1e-9 # Convert: [nM]->[M]
    
    koff=1/tau_minc
    kon=-koff**2*((tau_minc-tau_maxc)/(minc-maxc))
    N=koff/(A_minc*kon*minc)
    
    #### mono_tau vs c
    p0=[koff,kon]
    sigma=(df_stats.loc[:,('mono_tau_lin',low_tau)]+df_stats.loc[:,('mono_tau_lin',up_tau)])*1
    popt_tauc,pcov_tauc=curve_fit(varfuncs.tauc_of_c,
                             df_stats.conc*1e-9,
                             df_stats.loc[:,('mono_tau_lin',center_tau)],
                             p0=p0,
                             sigma=sigma,
                             absolute_sigma=True)
    perr_tauc = np.sqrt(np.diag(pcov_tauc))
    #### 1/mono_A vs c
    p0=[kon/koff,1e-3]
    if fix_SDS: # Set fixed offset=0 for SDS
        p0=[kon/koff]
        print('Fixed offset=0 for 1/A vs c')
    else:
        p0=[kon/koff,1e-3]
    sigma=(df_stats.loc[:,('mono_A_lin',low_A)]+df_stats.loc[:,('mono_A_lin',up_A)])/df_stats.loc[:,('mono_A_lin',center_A)]**2
    popt_A,pcov_A=curve_fit(varfuncs.Ainv_of_c,
                          df_stats.conc*1e-9,
                          1/df_stats.loc[:,('mono_A_lin',center_A)],
                          p0=p0,
                          sigma=sigma,
                          absolute_sigma=True)
    perr_A=np.sqrt(np.diag(pcov_A))
    ##### mono_tau vs 1/mono_A
    if fix_SDS: # Set fixed N=1 for SDS
        p0=[koff]
        print('Fixed N=1 for tauc vs. 1/A ')
    else:
        p0=[koff,N]
        
    sigma=(df_stats.loc[:,('mono_tau_lin',low_tau)]+df_stats.loc[:,('mono_tau_lin',up_tau)])*1
    popt_mix,pcov_mix=curve_fit(varfuncs.tauc_of_Ainv,
                             1/df_stats.loc[:,('mono_A_lin',center_A)],
                             df_stats.loc[:,('mono_tau_lin',center_tau)],
                             p0=p0,
                             sigma=sigma,
                             absolute_sigma=True)
    perr_mix=np.sqrt(np.diag(pcov_mix))
    ##### tau_d vs c
    df_stats['fit_taud']=varfuncs.taud_of_tauc(df_stats.loc[:,('mono_tau_lin',center_tau)],popt_mix[0]).values
    
    if fix_SDS: # Set fixed offset=0 for SDS
        p0=[koff]
        print('Fixed offset=0 for taud vs c')
    else:
        p0=[koff,1e-3]
    popt_taud,pcov_taud=curve_fit(varfuncs.taudinv_of_c,
                          df_stats.conc*1e-9,
                          1/df_stats.loc[:,'fit_taud'],
                          p0=p0,
                          sigma=None,
                          absolute_sigma=False)
    perr_taud=np.sqrt(np.diag(pcov_taud))
    ##### tau_d vs c (Picasso)
    if fix_SDS: # Set fixed offset=0 for SDS
        p0=[koff]
        print('Fixed offset=0 for taud_pic vs c')
    else:
        p0=[koff,1e-3]
    popt_taud_pic,pcov_taud_pic=curve_fit(varfuncs.taudinv_of_c,
                          df_stats.conc*1e-9,
                          1/df_stats.loc[:,('tau_d',center_A)],
                          p0=p0,
                          sigma=None,
                          absolute_sigma=False)
    perr_taud_pic=np.sqrt(np.diag(pcov_taud_pic))
    
    #### Assign fit results to df_fit
    df_fit=pd.DataFrame([],index=['tau_conc','A_conc','tau_A','taud_conc','taud_pic'])
    df_fit=df_fit.assign(popt=[popt_tauc,popt_A,popt_mix,popt_taud,popt_taud_pic])
    df_fit=df_fit.assign(perr=[perr_tauc,perr_A,perr_mix,perr_taud,perr_taud_pic])
    
    #### Assign number of docking sites to df
    for expID in df_stats.index:
        df.loc[expID,'n_ac']=(df_stats.loc[expID,'fit_taud'].values*popt_mix[0])/df.loc[expID,'mono_A_lin'].values
        
    return df,df_stats,df_fit

#%%
def _plot(df_stats,df_fit,use_tau_stat='mean',use_A_stat='median'):
    

    #### Which statistical quantity for mono_tau is used 
    if use_tau_stat=='mean':
        center_tau='mean'
        low_tau='std'
        up_tau='std'
    elif use_tau_stat=='median':
        center_tau='50%'
        low_tau='25%'
        up_tau='75%'
    else:
        center_tau='mean'
        low_tau='std'
        up_tau='std'
    #### Which statistical quantity for mono_A is used
    if use_A_stat=='mean':
        center_A='mean'
        low_A='std'
        up_A='std'
    elif use_A_stat=='median':
        center_A='50%'
        low_A='25%'
        up_A='75%'
    else:
        center_A='50%'
        low_A='25%'
        up_A='75%'
    
    import matplotlib.pyplot as plt
    import varfuncs
    
    f=plt.figure(num=11,figsize=[7,6])
    f.subplots_adjust(bottom=0.1,top=0.99,left=0.1,right=0.99,wspace=0.3,hspace=0.3)
    f.clear()
    
    ################################################ mono_tau vs concentration
    field='mono_tau_lin'
    x=df_stats.conc
    x_inter=np.arange(0,x.max(),0.1)
    y=df_stats.loc[:,(field,center_tau)]
    yerr=[df_stats.loc[:,(field,low_tau)],df_stats.loc[:,(field,up_tau)]]
    popt=df_fit.loc['tau_conc','popt']
    
    ax=f.add_subplot(221)  
    ax.errorbar(x,y,yerr=yerr,fmt='o',label='data')
    ax.plot(x_inter,varfuncs.tauc_of_c(x_inter*1e-9,*popt),'-',c='r',lw=2,label='fit')
    ax.set_xlabel('Concentration (nM)')
    ax.set_ylabel(r'$\tau_c$ (s)')
    ax.legend(loc='upper right')
    
    ################################################ 1/mono_A vs concentration
    field='mono_A_lin'
    x=df_stats.conc
    x_inter=np.arange(0,x.max(),0.1)
    y=1/df_stats.loc[:,(field,center_A)]
    yerr=[df_stats.loc[:,(field,low_A)]/df_stats.loc[:,(field,center_A)]**2,
          df_stats.loc[:,(field,up_A)]/df_stats.loc[:,(field,center_A)]**2]
    popt=df_fit.loc['A_conc','popt']
    
    ax=f.add_subplot(222)
    ax.errorbar(x,y,yerr=yerr,fmt='o',label='data')
    ax.plot(x_inter,varfuncs.Ainv_of_c(x_inter*1e-9,*popt),'-',c='r',lw=2,label='fit')
    ax.axhline(0,ls='-',lw=1,c='k')
    ax.axvline(0,ls='-',lw=1,c='k')
    ax.set_xlabel('Concentration (nM)')
    ax.set_ylabel(r'$1/A$ (a.u.)')
    ax.legend(loc='upper center')
    
    ################################################ mono_tau vs 1/mono_A
    field='mono_tau_lin'
    y=df_stats.loc[:,(field,center_tau)]
    yerr=[df_stats.loc[:,(field,low_tau)],df_stats.loc[:,(field,up_tau)]]
    field='mono_A_lin'
    x=1/df_stats.loc[:,(field,center_A)]
    xerr=[df_stats.loc[:,(field,low_A)]/df_stats.loc[:,(field,center_A)]**2,
          df_stats.loc[:,(field,up_A)]/df_stats.loc[:,(field,center_A)]**2]
    x_inter=np.arange(0,x.max()+0.2,0.1)
    popt=df_fit.loc['tau_A','popt']
    
    ax=f.add_subplot(223)
    ax.errorbar(x,y,xerr=xerr,yerr=yerr,fmt='o',c='k',label='data')
    ax.plot(x_inter,varfuncs.tauc_of_Ainv(x_inter,*popt),'-',c='r',lw=2,label='fit')
    ax.set_xlabel(r'$1/A$ (a.u)')
    ax.set_ylabel(r'$\tau_c$ (s)')
    ax.legend(loc='upper right')
    
    ###############################################################  1/fit_taud vs conc
    ax=f.add_subplot(224)
    
    field='fit_taud'
    x=df_stats.conc
    x_inter=np.arange(0,x.max(),0.1)
    y=1/df_stats[field]
    popt=df_fit.loc['taud_conc','popt']
    
    ax.errorbar(x,y,fmt='o',c='r',label='ac')
    ax.plot(x_inter,varfuncs.taudinv_of_c(x_inter*1e-9,*popt),'-',c='r',lw=2,label=None)
    
    field='tau_d'
    x=df_stats.conc
    x_inter=np.arange(0,x.max(),0.1)
    y=1/df_stats[(field,center_A)]
    popt=df_fit.loc['taud_pic','popt']
    
    ax.errorbar(x,y,fmt='o',c='b',label='pic')
    ax.plot(x_inter,varfuncs.taudinv_of_c(x_inter*1e-9,*popt),'-',c='b',lw=2,label=None)
    
    ax.axhline(0,ls='-',lw=1,c='k')
    ax.axvline(0,ls='-',lw=1,c='k')
    ax.set_xlabel('Concentration (nM)')
    ax.set_ylabel(r'$1/\tau_d$ (Hz)')
    ax.legend(loc='upper center')