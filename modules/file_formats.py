# Load packages
import h5py as h5py #hdf5 handling
import yaml
import numpy as np

############################################################### Read-in of hdf5-files
#%%
def read_locs(path):
    # Open locs_picked.hdf5 file
    locs_file=h5py.File(path,'r')
    # Load dataset 'locs' into np.array 'locs'
    locs=locs_file['locs'][...]
    locs_file.close()
    # Sort locs after groups and frames
#    locs.sort(order=['group','frame'],axis=0)
    
    return locs
#%%
def read_groupprops(path):
    
    groupprops_file=h5py.File(path,'r')
    groupprops=groupprops_file['locs'][...]
    groupprops_file.close()
    
    return groupprops
#%%
def read_pickprops(path):
    
    pickprops_file=h5py.File(path,'r')
    for name in pickprops_file: print(name)
    pickprops=pickprops_file['groups'][...]
    pickprops_file.close()
    
    return pickprops
############################################################### Save in hdf5-files
#%%
def save_locs(locs,path):
    # Save groupprops in hdf5 file
    locs_file = h5py.File(path,"w")
    dset=locs_file.create_dataset("locs", np.shape(locs), dtype=locs.dtype)
    dset[...]=locs
    locs_file.close() 
    return
#%%           
def save_locs_segments(locs_list,path):
    size = len(locs_list)
   
    for i in range(0, size):
        # Create savepath
        save_path = path.replace('.hdf5','_'+str(i+1) + '_of_' + str(size)+'.hdf5')
        # Create hdf5 container
        hf = h5py.File(save_path,'w')
        # Dump locs in container
        hf.create_dataset('locs', data = locs_list[i])       
        hf.close()
    return
############################################################### locs file manipulation (combine groups, segment by time,...)
#%%
def combine_locs(path,path_save):
   # Open first locs file 
   locs_file=h5py.File(path[0],'r')
   # Load dataset into locs
   locs=locs_file['locs'][...]
   
   for p in range(1,len(path)):
        # Open locs_picked.hdf5 file
        locs_file=h5py.File(path[p],'r')
        # Load dataset 'locs' into np.array 'locs'
        locs=np.append(locs,locs_file['locs'][...])
        locs_file.close()

   # Save combined locs
   locs_file_save = h5py.File(path_save, "w")
   dset=locs_file_save.create_dataset("locs", np.shape(locs), dtype=locs.dtype)
   dset[...]=locs
   locs_file_save.close()
   
   return locs
#%%
def segment_locs(path, NoFrames_new, NoSegments):
    # Read in locs-file
    locs=read_locs(path)
    # Sort after frames
    locs.sort(order=['frame'],axis=0)
    locs_list = []
    start = 0
    end = 0
    upper_boarder = NoFrames_new
    
    # run over all segments
    for i in range(0, NoSegments): 
        # run over all entries with frame number within the selected segment
        for j in range(start, len(locs)):     
            # increment end for each entry with frame number within boarders
            if locs[j][0] < upper_boarder:
                end += 1
            # break, if the frame number exceeds the segment
            else:
                break
        # append a segment to the list by truncating the original array
        locs_list.append(locs[start:end])
        # adapt the frame number to start from 0 for each segment
        locs_list[i]['frame'][:] = locs_list[i]['frame'][:] % NoFrames_new
        # make the end point the new starting point for the next segment
        start = end
        # increase the upper boarder for the frame number for the next segment 
        upper_boarder += NoFrames_new
        
    return locs_list
############################################################### Read and create meta data in yaml format
#%%
def read_meta(path):
    # Read in .yaml file generated by picasso
    stream=open(str.replace(path,'.hdf5','.yaml'))
    doc=yaml.load_all(stream)
    
    i=0
    for data in doc:
        if(i==0): TIFmeta=data
        if(i==1): LOCmeta=data
        i=i+1
    
    stream.close()
    
    return [TIFmeta,LOCmeta]
#%%
def create_meta_locs2groupprops(path,ADDdict,extension='_groupprops.yaml'):
    # Read in yaml.file generated by Picasso
    [TIFdict,LOCdict]=read_meta(path)
    
    # open .yaml file generated by picasso
    with open(str.replace(path,'.hdf5',extension),'w') as yaml_file:
        # Copy old yaml file into new yaml file
        yaml.dump(TIFdict,yaml_file,default_flow_style=False)
        yaml.dump(LOCdict,yaml_file,default_flow_style=False,explicit_start=True)
        # Add ADDdict to yaml file
        yaml.dump(ADDdict,yaml_file,default_flow_style=False,explicit_start=True)
        
    return
#%%
def create_meta_simulate(path,TIFdict,LOCdict):
    
    with open(path.replace('.hdf5','.yaml'),'w') as yaml_file:
        # Copy old yaml file into new yaml file
        yaml.dump(TIFdict,yaml_file,default_flow_style=False)
        yaml.dump(LOCdict,yaml_file,default_flow_style=False,explicit_start=True)
        
    return
#%%
def create_meta_segments(path,NoSegments,NoFrames_new):
    size = NoSegments
    # Get TIFdict and LOCdict
    [TIFdict,LOCdict]=read_meta(path)
    # Adapt number of frames for each yaml file
    TIFdict.update({'Frames': int(NoFrames_new)})
    
    for i in range(0, size):
        # Create savepath
        save_path = path.replace('.hdf5','_'+str(i+1) + '_of_' + str(size)+'.hdf5')
        with open(save_path.replace('.hdf5','.yaml'),'w') as yaml_file:
        # Copy old yaml file into new yaml file
            yaml.dump(TIFdict,yaml_file,default_flow_style=False)
            yaml.dump(LOCdict,yaml_file,default_flow_style=False,explicit_start=True)
            
    return

